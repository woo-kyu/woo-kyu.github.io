---
layout: single
title: "Ensemble (Complex)"
categories: ML
tag: [ML]
author_profile: false
search: true
use_tex: true
---

> Ensemble learning 은, 여러 개의 모델을 학습 시켜, 다양한 예측 결과들을 이용하는 방법론으로, 모든 machine learning model 과, <span style='color:green'>regression, classification 문제 모두 적용 가능</span>하다. 보통 Decision Tree 에서 자주 사용한다.

<img width="919" alt="Screenshot_2023-03-13_at_10 40 51_AM" src="https://github.com/woo-kyu/woo-kyu.github.io/assets/102133610/8b69d40a-7414-4e4e-bdd1-fbcf5b3a7408">{: .align-center}

<br>

## Bootstrap

- Parameter 의 분포를 정확하게 추정하기 위해서는 많은 표본 data sets 이 필요하다.
- 현재 가지고 있는 샘플을 Sampling with replacement 하여, 여러 개(B 개)의 data sets 을 만든다.

  $\sigma_\alpha = \sqrt{\frac1{B-1}\sum^B_{i=1}(\hat{\alpha_i}-\frac 1 B \sum ^B_{j=1}\hat\alpha_j)^2}$

  <img width="620" alt="Screenshot_2023-03-13_at_10 49 42_AM" src="https://github.com/woo-kyu/woo-kyu.github.io/assets/102133610/220fdc6a-f22a-4326-b965-5756afb1dbdf">{: .align-center}

<br>

### Bootstrap with n obs

- j-th 샘플이 <span style="color:skyblue">첫 번째</span> bootstrap observation 으로 뽑히지 않을 확률 : $(1-\frac1 n)$
- j-th 샘플이 <span style="color:skyblue">두 번째</span> bootstrap observation 으로 뽑히지 않을 확률 : $(1-\frac1 n)$
- <span style="color:skyblue">전체 bootstrap sample</span> 에 j-th 샘플이 포함되지 않을 확률 : $(1-\frac1 n)^n$
- 데이터 개수 <span style="color:skyblue">N이 충분히 많을 때</span> : $\underset{n \to \infty}{\lim}(1-\frac1n)^n=\frac1e$
- <span style="color:skyblue">B개의 bootstrap data sets</span> 를 생성했을 때, j-th  샘플이 없는 데이터 셋의 비율 : $\frac 1e \approx 1/3$