---
layout: single
title: "K-Means"
categories: ML
tag: [ML]
author_profile: false
search: true
use_tex: true
---

> K-평균(K-means) 알고리즘은 주어진 데이터를 K개의 클러스터로 그룹화하는 비지도 학습 방법으로, 데이터 포인트들을 가장 가까운 중심점(centroid)에 할당하고, 
> 그 다음 중심점을 해당 클러스터의 평균 위치로 업데이트하는 과정을 반복하여, 데이터 포인트들을 유사한 특성을 가진 K개의 클러스터로 분할한다.


# K-Means

---

---

Clustering with based on <span style='color:#ff7fff'>centroid(중심점)</span> of cluster

샘플은 most nearly centrobaric point 를 가진 cluster 로 assignment (할당)

K-means Algorithm 은 사전에 number of cluster 에 대한 hyper-parameter, k 를 define 해야 한다.

<img width="771" alt="image" src="https://github.com/woo-kyu/woo-kyu.github.io/assets/102133610/008ca41f-9e1f-42c0-bfce-97564f062d69">{: .align-center}

<span style='color:#ff7fff'>EM Algorithm</span> 을 통해, optimized cluster 에 converge(수렴) 할 때 까지 학습

<br>

## EM Algorithm

Maximum likelihood (최대 가능도) 또는 maximum a posteriori 를 갖는, parameter(모수)의 assumption value 를 찾는 iterative algorithm.

EM algorithm 은 <span style='color:#66cc66'>Expectation step</span> 과 <span style='color:##3399ff'> Maximization step</span> 으로 구분

- Expectation (기대값) step :
  - <span style='color:#66cc66'>현재의 추정된 parameter 를 통해 샘플을 cluster 에 assignment</span> 하는 단계
- Maximization (최대화) step :
  - <span style='color:##3399ff'>Likelihood (로그 가능도) 의 기댓값을 maximization 하는 parameter 를 estimation</span> 하는 단계

특정 distribution 에 대한 assumption 이 없는 Non-Parametric estimation 에서는 likelihood 의 개념이 없다.

Mean Shift 나 DBSCAN 의 estimate method of density 로 학습

K-means clustering 에서의 EM Algorithm 은,

- Expectation step :
  - Estimation 하고자 하는 parameter 는 cetroid 이므로, <span style='color:#66cc66'>sample 을 군집으로 assignment</span> 하는 단계
- Maximization step :
  - Likelihood 를 sample 이 cluster 에 속할 확률로 해석하여, <span style='color:##3399ff'>cluster 에 assign 된 샘플을 base 로, 새로운 cetroid point 를 계산</span>

<br>

# E.g., K-means Clustering

---

---

### number of cluster is 2

<img width="366" alt="1" src="https://github.com/woo-kyu/woo-kyu.github.io/assets/102133610/dc284aeb-88d6-407e-9b4a-6861c617a921">{: .align-center}

<br>

### 처음 cluster’ centroid 는 set random

<img width="367" alt="2" src="https://github.com/woo-kyu/woo-kyu.github.io/assets/102133610/f3c9f35d-8fd9-489d-9f2d-1bb1a86d6ac4">{: .align-center}

<br>


### Samples 를 <span style='color:#66cc66'>most nearly centroid 에 assignment</span> 하여 cluster 를 생성 (Expectation)

<img width="402" alt="3" src="https://github.com/woo-kyu/woo-kyu.github.io/assets/102133610/12cc4077-d25a-4317-bad6-4bbaa18e3247">{: .align-center}

<br>

### Cluster 의 <span style='color:##3399ff'>새로운 centroid 를 계산</span> (Maximization)

<img width="403" alt="4" src="https://github.com/woo-kyu/woo-kyu.github.io/assets/102133610/97252a5c-7348-47c9-9a17-c42f96548315">{: .align-center}

<br>

### Sample 을 <span style='color:#66cc66'>most nearly centroid 에 re-assignment</span> 하여 cluster 생성 (Expectation)

<img width="400" alt="5" src="https://github.com/woo-kyu/woo-kyu.github.io/assets/102133610/f978bd8f-fac2-4f19-bc51-c8de55414bf4">{: .align-center}

<br>


### Cluster 의 <span style='color:##3399ff'>새로운 Centroid 를 계산</span> (Maximization)

<img width="405" alt="6" src="https://github.com/woo-kyu/woo-kyu.github.io/assets/102133610/d7726565-be3e-4fcd-8ba3-131b97002d6a">{: .align-center}

<br>


# Evaluation Metrics of Clustering

---

---

## Silhouette coefficient

Most nearby other cluster’s distance 를 통해 계산

Silhouette coefficient have a between -1 to 1 value. nearby 1 is better

<img width="381" alt="7" src="https://github.com/woo-kyu/woo-kyu.github.io/assets/102133610/61929645-b446-42db-ad6f-e1440e7a8777">{: .align-center}

<br>

## Silhouette analysis

clusters 들이 얼마나 efficient 하게 분리되어 있는 지를 보여준다.

Each sample 들이 가지고 있는 Silhouette coefficient 를 기반으로 한다.

전체 Silhouette coefficient’ average 가 클수록, 개별 cluster 의 average’s deviation 이 작을 수록 좋다.

Silhouette coefficient 의 average 가 크고, deviation 이 작도록, K-means algorithm 의 number of cluster, (k) 를 결정한다.

<img width="559" alt="8" src="https://github.com/woo-kyu/woo-kyu.github.io/assets/102133610/fa9ffb60-8c43-41c8-97c6-81496fc670ac">{: .align-center}

Figure 1

<br>

<img width="571" alt="10" src="https://github.com/woo-kyu/woo-kyu.github.io/assets/102133610/cbf518e0-7a79-40cc-9474-fb7c07b3ac6e">{: .align-center}

Figure 2

<br>

# K-means’s uppermost limit

- <span style='color:#ff7fff'>Number of cluster, set first value of centroid</span> 에 따라 performance deviation(편차) 의 차이가 크다.
- <span style='color:#ff7fff'>Cluster 의 size 나 density 가 다를 경우</span>, 학습이 어려울 수 있다.
- <span style='color:#ff7fff'>Data distribution 이 특이할 경우</span>, cluster learning 이 어렵다

  <img width="583" alt="11" src="https://github.com/woo-kyu/woo-kyu.github.io/assets/102133610/452d13bd-7d53-4ae4-9135-e902f994d379">{: .align-center}


